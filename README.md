# README.md 
--

To run the maze program visit the `test_maze.py` script which runs the HMM localizer as well as creates a Maze object (uncomment whichever maze you would like to use). In order to change the starting location of the robot or create your own maze, please go to one of the `.maz` files and change it accordingly. 

*Maze Model:* The maze model for this problem mirrored that created in PA2 and much of the code I wrote came from there. To fit the problem, the tiles were all colored with a letter `r,g,b,y` corresponding to red, green, blue, and yellow. The model then stored these floor colors as values which the robot sensor would read. Additionally, I added functionality to record the location of the walls as the setup of the maze is known for the localization problem. 

*Robot/Sensor Model:* The sensor model used the required 88% accuracy for readings and the converse 4% for each other color. Additionally, as specified by the prompt, I had the robot traverse a path and then analyzed each successive step while storing the direction as well as a ground truth to compare against. During the prediction phase, I printed the maze map and the probabilities of each square as though the robot was moving. Also, I took the first reading at the point the robot was dropped not after the first move. The letter `A` signifies the robot in these visualizations. 

*Particle Filtering Algorithm:* For the particle filter algorithm, I settled on the linear algebra approach with a few modifications that seemed logical for the problem. The algorithm is composed of three steps, the prior step, prediction step, and the update step. The first time around for the prior step, the algorithm initialized the robot probability to 1/the number of empty squares for each empty square. From there, the prediction step involved guessing where the robot would move next with a probability of `0.25` for each direction if they were all unobstructed. If one of the directions was obstructed then the point the robot was hypothetically on would also get a score of 0.25 added to it for the number of obstructed sides (the blind robot cannot tell where the walls and borders are so may decide to move in those directions. It worked particularly well for those scenarios where all four sides were blocked and a robot was initialized in the middle as the algorithm would converge very quickly. Then, in the upgrade step, I took the sensor reading and multiplied the probability of the correct sensor reading (0.88) to the squares with that color value while multiplying the other squares by the incorrect sensor reading probability (0.04). Walls were also checked here and assigned the probability of 0 as the robot could not go there. Then I took the prior and current matrices and performed the element wise multiplication of the filtering formula. I then set the current matrix to the prior one. From there, I normalized the outputs by creating a spread that should add up to the number one and then from there also rounded the numbers to 3 decimal places for simplicity. It should be noted that by doing this many very small probabilities then evaluated to 0 in the printed matrix, but were not unless they denoted the presence of a wall. Then the algorithm continued on for the max number of iterations as specified in the constructor. Each iteration I printed the ground truth location list, the maze and the prediction matrix with probabilities. 
